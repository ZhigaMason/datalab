---
title: "01_eda"
author: "Maksym Khavil"
date: "2025-07-15"
output: 
    html_document:
        toc: true
        theme: yeti
        number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading data

The dataset is loaded using a function from `R/load_data.R` script, we will also load required libraries.

```{r}
library(corrplot)

source(here::here("R", "constants.R"))
source(here::here("R", "load_data.R"))

data = load_bank_data()
data
```
Let us separate the data into positive and negative samples for the ease of further analysis.

```{r}
pos_labeled = data[data$y == "yes",]
neg_labeled = data[data$y == "no",]
print(sprintf("Number of positive samples: %d", nrow(pos_labeled)))
print(sprintf("Number of negative samples: %d", nrow(neg_labeled)))
print(sprintf("Positive rate:              %.3f", nrow(pos_labeled) / nrow(data)))
```

It is clear that data is strongly skewed towards negative outcome (the contacted person has not subscribed to the deposit) with only 11.5% of samples being positive.

## Binary Data Analysis

We will plot contingency tables between binary features and target variable to investigate their relations. We want to check if those variables interact with target variable in any way.

```{r}
par(mfrow=c(1, 3))

ct = table(data$default, data$y)
mosaicplot(
    ct, ylab="Subscribed to Deposit", xlab="Has Credit in Default",
    main="Label X Default"
    
)

ct = table(data$housing, data$y)
mosaicplot(
    ct, ylab="Subscribed to Deposit", xlab="Has Housing Loan",
    main="Label X Housing "
)

ct = table(data$loan, data$y)
mosaicplot(
    ct, ylab="Subscribed to Deposit", xlab="Has Personal Loan",
    main="Label X Loan "
)
```

Mosaic plots show that standalone **default** feature does not differentiate between target classes, due to its values being extrmely skewed towards negative answer and both groups have similar proportions of people subscribed to deposit.

Feature **loan**, representing whether the client has a personal loan, is also dominated by negative answers, though not as severe as **default**, and a population without the personal loan is more likely to subscribe to deposit.

The biggest distinction between target classes is given by **housing**, a feature indicating if client has housing loan. It is balanced between two classes and a person that had not borrowed for a house is more likely to subscribe to term deposit.


## Multiclass Data analysis

For each multiclass feature we will plot absolute counts and rates of both classes to examine feature structure and interactions with target variable. By those means we want to understand whether different classes are more favorable to subscribe to the deposit, as well as study class distributions.

```{r}
plot_count_bars <- function(col, ...) {
    pos <- aggregate(x = list(count = pos_labeled$y), by = list(column = pos_labeled[,col]), FUN = length)
    neg <- aggregate(x = list(count = neg_labeled$y), by = list(column = neg_labeled[,col]), FUN = length)
    data_matrix <- matrix(
        c( pos$count,  neg$count), nrow = 2, byrow = TRUE
    )
    colnames(data_matrix) <- pos$column
    rownames(data_matrix) <- c("Pos. Cnt", "Neg. Cnt")
    barplot(
        data_matrix,
        beside = TRUE,
        legend = rownames(data_matrix),
        main = sprintf("Class Counts X %s", col),
        xlab = col, ylab = "Class Counts",
        ...
    )
    grid()
}

plot_rate_bars <- function(col, ...) {
    par(mar=c(5, 4, 6, 2))
    total_cnt <- aggregate(x = list(count = data$y), by = list(column = data[,col]), FUN = length)$count
    pos <- aggregate(x = list(count = pos_labeled$y), by = list(column = pos_labeled[,col]), FUN = length)
    neg <- aggregate(x = list(count = neg_labeled$y), by = list(column = neg_labeled[,col]), FUN = length)
    data_matrix <- matrix(
        c( pos$count / total_cnt,  neg$count / total_cnt), nrow = 2, byrow = TRUE
    )
    colnames(data_matrix) <- pos$column
    rownames(data_matrix) <- c("Pos. Rate", "Neg. Rate")
    barplot(
        data_matrix,
        main = sprintf("Class Rates X %s", col),
        ylim=c(0,1),
        xlab = col, ylab = "Class Rates",
        ...
    )
    grid()
    legend(
        "topright",
        legend = rownames(data_matrix),
        xpd = T,
        fill=c("black", "grey"),
        inset=c(0, -0.2)
    )
}
```

### Job

```{r}
plot_count_bars("job", cex.names = 0.7, las=2)

plot_rate_bars("job", cex.names = 0.7, las=2)
```
Most of population is employed in management or as a technician and blue-collar workers. Other large categories include administration and service. Every job group shows results, that are similar to the whole data-set, i.e. positive rate close to 10%, except for *retired*, *students* and *unknown*. That is an interesting phenomenon that can be checked later during statistical testing.

### Marital Status

```{r}
plot_count_bars("marital")

plot_rate_bars("marital")
```

Most of the contacted people were married, but they were the least likely to subscribe to the deposit, though the difference may be insignificant.

### Education

```{r}
plot_count_bars("education")

plot_rate_bars("education")
```

People with secondary education are the biggest fraction of those who took part in the data collection process, it is no surprise, as secondary education is obligatory. Despite the difference in past all three groups agree on data-set wide positive rate of around 10%. Maybe combinations with other categorical and numerical features will be able to help us reveal patterns behind people subscribing, but education alone does not provide with any insights.

### Contact

```{r}
plot_count_bars("contact")
plot_rate_bars("contact")
```

Cellular calls were the most frequent form of communication. Unlabeled records also present a large part of population, while the telephone category is the least prominent. With such distribution of values, we should ask our selves, whether there are any benefits in keeping  **contact** feature with almost a third of its records being unknowns, and the rest primarily binned into single category. More over cellular and telephone positive rates are very close and the distinction may in insufficient to provide any knowledge.

### Outcome of previous campaign

```{r}
plot_count_bars("poutcome")
plot_rate_bars("poutcome")
```

Most of previous outcomes are *unknown*, that is most of people had not been contacted before the campaign. Rates shows, that people who has subscribed during the last campaign, are the most likely to subscribe to the current campaign, while those who was not affected by previous campaign show opposite dynamic.

## Numerical Data

We will plot box-plots of numerical features against target variable overall dataset histogram to study univariate distributions and interactions with target variable.

```{r}
boxplot_mean <- function(col_name, fctr='y') {
    formula = as.formula(paste(col_name, "~", fctr))
    boxplot(formula, data) 
    grid()
    means <- aggregate(formula, data, FUN=mean)[,col_name]
    points(
        1:length(unique(data[,fctr])), means, pch=17
    )
    legend("topright", legend="â–² Means")
}

histogram_desc <- function(col_name, ...) {
    col_data = data[,col_name]
    hist(
        col_data,
        xlab = col_name,
        ...
    )
    abline(v=mean(col_data), col = "red", lwd=3)
    abline(v=median(col_data), col = "orange", lwd=3)
    qs = quantile(col_data, probs=c(0.25, 0.75))
    segments(
        x0=qs["25%"], y0=0, x1=qs["75%"], y1=0, col = "yellow", lwd=3
    )
    legend(
        "topright",
        legend = c("Mean", "Median", "IQR"),
        col = c("red", "orange", "yellow"),
        pch = c(15, 15, 17)
    )
}
```

### Age

```{r}
boxplot_mean("age")
title("Label X Age")

histogram_desc("age", main = "Histogram of Age")
```

Boxes-and-whispers of both classes are very similar with median 39 and 40 and almost identical means. Population that has not subscribed has slightly lower range. The dataset histograms gravitates towards 30 years, we also see a suffen drop at 60 years, this could be a bias introduced during data engineering process, we should check for that during hypothesis testing.

### Balance

```{r}
boxplot_mean("balance")
title("Label X Balance")
histogram_desc("balance", main = "Histogram of Balance", xlim=c(-2000, 20000), breaks = 100)
```

Both ranges are squashed, due to extreme values at the positive tail of distributions. During our modelling step we shall pay great attention to outliers, as they may overinfluence our model.

We have clipped the histograms to display greater mass of values, due to the outlier that is easily to spot at the top of boxplot. We see that almost all records are contained within (-1000, 5000) interval and distribution has a spiky bell curve.

### Duration of Last Call

```{r}
boxplot_mean("duration")
title("Label X Last Call Duration (seconds)")
histogram_desc(
    "duration",
    main = "Histogram of Last Call Duration"
)
```

Here we see some real difference: positive population distribution is a lot wider with median 500 seconds = 8.3 minutes, while the other classes range just barely stretches over 500. We also see many outliers in both classes. Such sharp contrast may be instrumental to *yes* population, due to the deposit arranging taking longer time, than simply declining one.

The histogram follows shape of Poisson or Exponential distribution with a tail quickly vanishing after 1000 seconds.

### Number of Contacts during Campaign (campaign)

```{r}
boxplot_mean("campaign")
title("Label X Number of Contacts during Campaign")

histogram_desc(
    "campaign",
    main = "Histogram of Number of Contacts during Campaign",
    breaks = 50
)
```
This plot has a lot in common with **balance**. It also shows great number of outliers and range squeezed into bottomline. //add histograms

Histograms also shows fast rate of decay after 3 contacts per person, we may hypothesize that  **campaign** is distributed exponentially.

### Number of Days since Last Contact (pdays)

```{r}
boxplot_mean("pdays")
title("Label X Number of Days since Last Contact")

histogram_desc(
    "pdays",
    main = "Histogram of Number of Days since Last Contact",
)
```

This box-and-whispers graph follows path of **duration** with *yes* being stretched out into a year timespan, while *no* is smashed into zero. An important remark is that value of -1 indicates, that the call made is the first one. We hope that next plots will be able to make it clear, why value -1 is present in most samples.

### Number of Contacts before Campaign (previous)

```{r}
boxplot_mean("previous")
title("Label X Number of Contacts before Campaign")

histogram_desc(
    "previous",
    main = "Histogram of Number of Contacts before Campaign",
    breaks = 30
)
```

This pattern is very similar to the one for **balance** and **pdays**. Here it seems old clients are more eager to subscribe to deposit, than new clients, bases on the chart above.

We can also see that most people, who were contacted during the campaign, had no previous ties with the bank, thus **pdays** number of days since last contact is mostly -1.

## Feature interactions

We will check bivariate statistics such as correlation coefficient and plot box-plots. We hope to catch connections that are present in data, that omit direct target variable impact.

### Numerical to Numerical

We look at interactions between features. We will examine Pearson's and Spearman's correlation between every pair of numerical features.

```{r}
numeric_data <- data[sapply(data, is.numeric)]

cor_matrix <- cor(numeric_data, use = "pairwise.complete.obs", method="pearson")
corrplot(
    cor_matrix, method = "ellipse", type = "upper",  tl.col = "black", tl.cex = 0.8, addCoef.col = "black",
    title = "Pearson Correlation Matrix", mar = c(1, 1, 1, 1)
)

cor_matrix <- cor(numeric_data, use = "pairwise.complete.obs", method="spearman")
corrplot(
    cor_matrix, method = "ellipse", type = "upper",  tl.col = "black", tl.cex = 0.8, addCoef.col = "black",
    title = "Spearman Correlation Matrix", mar = c(1, 1, 1, 1)
)
```

Most features are uncorrelated, except **pdays** and **previous** that have Pearson's $r = 0.58$ and Spearman's $r = 0.98$ coeficients. Other notable, but relatively weak Pearson's correlations are **age**-**balance**, **day**-**duration**, **day**-**pdays**, **campaign**-**pdays**, **duration**-**campaign**, **day**-**previous**, **campaign**-**previous**. Spearman's correlation shows values of absolute value near 0.05 for most pairs, it is not clear whether it is significant, tests later should show.

### Categorical to Numerical

We will plot boxplots between numerical and categorical features. Due to a big number of vizualizations we will focus on peculiarities in data, with lesser comments on patterns.

```{r}
for (col in colnames(numeric_data)) {
    boxplot_mean(col, "default")
    title(sprintf("Default x %s", col))
}
```

Most boxplots show little to no distinction between **default** classes, but an interesting observation is that calls of **default**-positive population are slightly shorter.

```{r}
for (col in colnames(numeric_data)) {
    boxplot_mean(col, "housing")
    title(sprintf("Housing x %s", col))
}
```
Plots follow whole dataset dynamic, an interesting deviation is that a median and an average people, who have housing loan, are younger, than their counterpart, who does not have the loan.

```{r}
for (col in colnames(numeric_data)) {
    boxplot_mean(col, "loan")
    title(sprintf("Loan x %s", col))
}
```

Plots have no new information, one of reasons for that is personal loans are taken by most strats of population and with differing relationship with the bank.

```{r}
n_jobs = length(unique(data$job))
for (col in colnames(numeric_data)) {
    formula = as.formula(paste(col, "~", "job"))
    boxplot(formula, data, las=2) 
    grid()
    means <- aggregate(formula, data, FUN=mean)[,col]
    points(
        1:n_jobs, means, pch=17
    )
    legend("topright", legend="â–² Means")
    title(sprintf("Job x %s", col))
}
```

The only point of interest in plots above are higher-than-others values for **previous** in *student* job group. This maybe another data engineering bias, because it is common to use students for data collection campaigns and they might have also been a part of other research or have ties to the bank, nevertheless it is just a hypothesis, that can be checked later.

```{r}
for (col in colnames(numeric_data)) {
    boxplot_mean(col, "marital")
    title(sprintf("Marital Status x %s", col))
}
```

No visible difference between **marital** classes, except for *single* population being a lot younger than *divorced* and *married*.

```{r}
for (col in colnames(numeric_data)) {
    boxplot_mean(col, "education")
    title(sprintf("Education x %s", col))
}
```

No relations are seen between **education** and numerical values, slight deviations are present in **age** feature, those can be a result of ongoing trend of younger generations being educated more on average.

```{r}
for (col in colnames(numeric_data)) {
    boxplot_mean(col, "contact")
    title(sprintf("Contact x %s", col))
}
```

No significant dependancies can be recognized here as well.

## Treatment of 'unknown' values

Throughout this notebook we have seen that some categorical features have *unknown* records. Let us take a look at what fraction of population is affected by them.

```{r}
par(mar=c(5, 4, 4, 3))

categorical_data <- data[sapply(data, is.factor)]
unknown_data <- t(matrix(sapply(categorical_data, function(x) sum(x == "unknown"))))
colnames(unknown_data) <- colnames(categorical_data)
rownames(unknown_data) <- c("# of `unknown`")
barplot(
    unknown_data,
    las=2,
    cex.names = 0.8,
    ylab = "# of 'unknown'", main = "Absolute and Relative Number of Unknown Values",
    ylim = c(0, nrow(data))
)

par(new = T, mar=c(5, 4, 4, 3))
unknown_data_percent <- 100 * unknown_data / nrow(data)
barplot(
    unknown_data_percent,
    las=2,
    cex.names = 0.8,
    ylim = c(0, 100), axes=F
)
axis(side=4)
mtext("% of 'unknown'", side = 4, line =2)
grid()
```

Most features have no records or neglectible amounts of *unknown*. **education** and **job** have under 10% of their values, while **contact** has ~30% of its values as *unknowns*. The **poutcome** has over 80% of its values as unknowns. During modeling phase we should consider whether we want to use **contact** and **poutcome**.

## Conclusion

After thorough EDA we have collected a battery of knowledge to test against the data. Those include distribution types (normality of age, exponential for duration and number of calls), independence of categorical and numerical features (low correlation scores, similar box-plots over a feature) and their efficacy as predictors for whether a person gets subscribed or not (prevalence of single value through dataset in **pdays**, **poutcome**, **previous**). Specialized treatment should be given to outliers, that arise in every feature and impact it.
